{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWUsszxxiXPH",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fctMNraAwSdh",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device('cuda:0')\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    \n",
    " try:\n",
    "    from google.colab import drive\n",
    "    is_in_colab = True\n",
    "except:\n",
    "    is_in_colab = False\n",
    "\n",
    "if is_in_colab:\n",
    "    drive.mount('/content/drive')\n",
    "    data_folder = r'/content/drive/My Drive/Colab/IDAO_2020/'\n",
    "else:\n",
    "    data_folder = r'./data/'\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# баш команда для создания каталога в монитрованном гугл-диске, для хранения там данных. \n",
    "# Выполните один раз после монтирования диска, чтобы не создавать папку вручную\n",
    "# ! mkdir -p '/content/drive/My Drive/Colab/IDAO_2020/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRfDlcBTiid9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_folder + 'train.csv', parse_dates=['epoch']).iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i3nl9_iVcEl",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data.set_index(keys=data['sat_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJHqM3j3wVHt",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def split_data(values, coeff=0.7):\n",
    "  split = int(np.floor(coeff * values))\n",
    "  split2 = int(np.floor(values*(1-coeff)/2))\n",
    "  indices = list(range(values))\n",
    "  np.random.shuffle(indices)\n",
    "  train_indices, val_indices, test_indices = indices[:split], indices[split:split+split2], indices[split+split2:]\n",
    "  return train_indices, val_indices, test_indices\n",
    "\n",
    "train_indices, val_indices, test_indices = split_data(len(data['sat_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yHF-S2wQHAO",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = data.loc[train_indices]\n",
    "test_data = data.loc[test_indices]\n",
    "val_data = data.loc[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GE1FyDjbGX3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Data_Sat(Dataset):\n",
    "    def __init__(self, data, sequence_duration=20, normalizer=None):\n",
    "        self.sequence_duration = sequence_duration\n",
    "        self.data = data\n",
    "        self.satellite_dict = {}\n",
    "        self.normalizer = normalizer\n",
    "        self.split_data()\n",
    "\n",
    "    def split_data(self):\n",
    "      for ind, satellite in enumerate(self.data['sat_id'].unique()):\n",
    "            sat_data = self.data.query('sat_id==@satellite').iloc[:,1:]\n",
    "            sequence_count = np.floor(sat_data.shape[0] / self.sequence_duration).astype('int')\n",
    "\n",
    "            samples_sat = np.zeros((sequence_count * self.sequence_duration, 12))\n",
    "            samples_sat = sat_data.iloc[: sequence_count * self.sequence_duration].values\n",
    "            if self.normalizer:\n",
    "                samples_sat = self.normalizer.fit_transform(samples_sat)\n",
    "\n",
    "            self.satellite_dict[ind] = samples_sat.reshape(sequence_count, self.sequence_duration, 12)\n",
    "\n",
    "        \n",
    "        \n",
    "    def sample_generator(self, max_sequence_count=10):\n",
    "      self.samples = []\n",
    "\n",
    "      for sat in self.satellite_dict.values():\n",
    "        if sat.shape[0] > max_sequence_count:\n",
    "          sequence_count = sat.shape[0]\n",
    "          numb_samples = math.ceil(sequence_count / max_sequence_count)\n",
    "          step = (sequence_count - max_sequence_count)/(numb_samples-1)\n",
    "          for sample in range(numb_samples):\n",
    "            next_step = round(step*sample)\n",
    "            \n",
    "            self.samples.append(self.data_casting(sat[next_step: next_step + max_sequence_count]))\n",
    "            # break\n",
    "\n",
    "    def data_casting(self, data):\n",
    "      for i in range(6):\n",
    "        data[...,i+6] -= data[0, 0, i+6] - data[0, 0, i]\n",
    "      return data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns total number of samples\n",
    "        '''\n",
    "        return len(self.samples)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return torch.Tensor(self.samples[index]).type(torch.FloatTensor)\n",
    "\n",
    "dataset = Data_Sat(train_data, 20, Normalizer())\n",
    "dataset.sample_generator(max_sequence_count=100)\n",
    "print('Samples count:',len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dataset[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=1) as progress_bar:\n",
    "            for i, sample in enumerate(data):\n",
    "                sample = sample.permute(1, 2, 0, 3)\n",
    "                for sequence in sample:\n",
    "                    X_batch, y_batch = (sequence[...,6:]).to(device), (sequence[...,:6]).to(device)\n",
    "                    logits = model(X_batch)\n",
    "\n",
    "\n",
    "                    loss = criterion(logits, y_batch)\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    if optimizer:\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "#                     indices = torch.max(logits, dim=2)[1]   \n",
    "                # correct_samples = float(torch.sum(indices[y_batch!=0] == y_batch[y_batch!=0]))\n",
    "                \n",
    "                # cur_correct_count, cur_sum_count = correct_samples, y_batch[y_batch!=0].shape[0]\n",
    "\n",
    "                # correct_count += cur_correct_count\n",
    "                # sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
    "                    name, loss.item())\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
    "                name, epoch_loss)\n",
    "            )\n",
    "\n",
    "    return epoch_loss #/ batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=1,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=6, output_dim=6, lstm_hidden_dim=28, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 6, \n",
    "                            hidden_size = lstm_hidden_dim,\n",
    "                            num_layers = lstm_layers_count,\n",
    "                            bias=True)\n",
    "        \n",
    "        self.linear = nn.Linear(lstm_hidden_dim, 6, bias=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        lstm_out, _ = self.lstm.forward(inputs)\n",
    "        linear_out = self.linear.forward(lstm_out)\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LSTM().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=5)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "fit(model, criterion, optimizer, train_loader, epochs_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sequence_duration = 20\n",
    "val_dataset = Data_Sat(val_data, sequence_duration, Normalizer())\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "for batch in val_dataset.satellite_dict[1]:\n",
    "    model.train(False)\n",
    "    batch = batch.reshape(sequence_duration, 1, -1)\n",
    "    X_batch, y_batch = FloatTensor(batch[...,6:]), FloatTensor(batch[...,:6]).detach().to(\"cpu\").numpy().reshape(sequence_duration,-1)\n",
    "    \n",
    "    predict = model(X_batch).detach().to(\"cpu\").numpy().reshape(sequence_duration,-1)\n",
    "    with_model = predict - y_batch\n",
    "    without_model = X_batch.detach().to(\"cpu\").numpy().reshape(sequence_duration,-1) - y_batch\n",
    "    print(abs(with_model).sum())\n",
    "    print(abs(without_model).sum())\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "#     break\n",
    "#     scaler.fit(predict.detach())\n",
    "#     print(scaler.inverse_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNn/CRuVT+ZEGb/VmOyLWIL",
   "collapsed_sections": [],
   "name": "IDAO.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}