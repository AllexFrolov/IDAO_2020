{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDAO.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oWUsszxxiXPH",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fctMNraAwSdh",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "He4p9b4_5eRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device('cuda:0')\n",
        "    from torch.cuda import FloatTensor\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    from torch import FloatTensor\n",
        "    \n",
        "try:\n",
        "    from google.colab import drive\n",
        "    is_in_colab = True\n",
        "except:\n",
        "    is_in_colab = False\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "04cdSTyW5eRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# вывод информации о выданном с colab GPU\n",
        "if is_in_colab:\n",
        "    !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "    !pip install gputil\n",
        "    !pip install psutil\n",
        "    !pip install humanize\n",
        "    import psutil\n",
        "    import humanize\n",
        "    import os\n",
        "    import GPUtil as GPU\n",
        "    GPUs = GPU.getGPUs()\n",
        "    gpu = GPUs[0]\n",
        "    def printm():\n",
        "        process = psutil.Process(os.getpid())\n",
        "        print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "        print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "    printm()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "FSRHCdJl5eRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if is_in_colab:\n",
        "    drive.mount('/content/drive')\n",
        "    data_folder = r'/content/drive/My Drive/Colab/IDAO_2020/'\n",
        "else:\n",
        "    data_folder = r'./data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "qztGRXl25eRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# баш команда для создания каталога в монитрованном гугл-диске, для хранения там данных. \n",
        "# Выполните один раз после монтирования диска, чтобы не создавать папку вручную\n",
        "# ! mkdir -p '/content/drive/My Drive/Colab/IDAO_2020/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "JHbuGit85eRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(path, model, optimizer, loss_history, train_history, val_history):\n",
        "    torch.save({\n",
        "            'epoch': len(train_histor),\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss_history[-1],\n",
        "            'loss_history': loss_history,\n",
        "            'train_history': train_history,\n",
        "            'val_history': val_history\n",
        "            }, path)\n",
        "    print('successfully saved')\n",
        "    \n",
        "def load_model(path, model, optimizer, loss_history, train_history, val_history):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    loss_history = checkpoint['loss_history']\n",
        "    train_history = checkpoint['train_history']\n",
        "    val_history = checkpoint['val_history']\n",
        "    print('successfully loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "c4k2aUKI5eRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_delta_time(df, columns=None):\n",
        "    \"\"\"\n",
        "    Добавляет столбец delta_time в секундах. Возвращает DataFrame в порядке указанном columns\n",
        "    если columns нет то возвращает все столбцы\n",
        "    \"\"\"\n",
        "    \n",
        "        \n",
        "    df.sort_values(by=['sat_id', 'epoch'], inplace=True) \n",
        "    \n",
        "    df['delta_time'] = df.iloc[1:,1] - df.iloc[0:-1,1].values    \n",
        "    delta_time = df['delta_time']\n",
        "    df['delta_seconds'] = delta_time.dt.seconds\n",
        "    filters = data.iloc[:, 2] != np.insert(df.iloc[0:-1, 2].values, 0, -1)\n",
        "    df.loc[filters, ['delta_time', 'delta_seconds']] = 0\n",
        "    if not columns:\n",
        "        columns=df.columns\n",
        "    return df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "fu-0X06_5eRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Norm():\n",
        "    \"\"\"\n",
        "    Нормализатор. \n",
        "    Init запоминает среднее и стандартное отклонение в данных\n",
        "    \"\"\"\n",
        "    def __init__(self, df, ignore_column=None):\n",
        "        self.mean = df.mean()\n",
        "        self.std = df.std()\n",
        "        self.l2 = df.pow(2, axis=0).sum(axis=0).pow(0.5, axis=0)\n",
        "        if ignore_column:\n",
        "            self.mean[ignore_column] = 0\n",
        "            self.std[ignore_column] = 1\n",
        "            self.l2[ignore_column] = 1\n",
        "    @staticmethod\n",
        "    def columns_check(columns, df_columns):\n",
        "        if not columns:\n",
        "            return df_columns\n",
        "        return columns\n",
        "        \n",
        "    def z_norm(self, df, columns=None):\n",
        "        columns = columns_check(columns, df.columns)\n",
        "        return (df[columns] - self.mean[columns]) / self.std[columns]\n",
        "    \n",
        "    def l2_norm(self, df, columns=None):\n",
        "        columns = self.columns_check(columns, df.columns)\n",
        "        return df[columns] / self.l2[columns]\n",
        "        \n",
        "    def back_z_norm(self, df, columns=None):\n",
        "        try:\n",
        "            columns = columns_check(columns, df.columns)\n",
        "        except:\n",
        "            print(\"df должен быть DataFrame или columns должен быть заполнен\")\n",
        "            return None\n",
        "        if not type(df) is pd.core.frame.DataFrame:\n",
        "            df = pd.DataFrame(data=df, columns=columns)\n",
        "            \n",
        "    def back_l2_norm(self, df, columns=None):\n",
        "        try:\n",
        "            columns = columns_check(columns, df.columns)\n",
        "        except:\n",
        "            print(\"df должен быть DataFrame или columns должен быть заполнен\")\n",
        "            return None\n",
        "        if not type(df) is pd.core.frame.DataFrame:\n",
        "            df = pd.DataFrame(data=df, columns=columns)\n",
        "            \n",
        "        return (df[columns] * self.l2[columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJrY-r3-5eR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(values, coeff=0.9):\n",
        "    # coeff - доля трейна, остальное - \n",
        "    split = int(np.floor(coeff * values))\n",
        "    indices = list(range(values))\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[:split], indices[split:]\n",
        "    return train_indices, val_indices\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nli8oJYa5eR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_folds(indices, n_folds):\n",
        "    # делит список индексов на n_folds частей\n",
        "    avg = len(indices) / float(n_folds)\n",
        "    result = []\n",
        "    last = 0.0\n",
        "    while last < len(indices):\n",
        "        result.append(indices[int(last):int(last + avg)])\n",
        "        last += avg\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_GE1FyDjbGX3",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "class Data_Sat(Dataset):\n",
        "    def __init__(self, data, sequence_length=20):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.data = data\n",
        "        self.satellite_dict = {}\n",
        "        self.split_data()\n",
        "\n",
        "    def split_data(self):\n",
        "        # разделяет данные по каждому спутнику на отдельные секвенции длиной sequence_length каждая\n",
        "        # и записывает их в словарь self.satellite_dict\n",
        "\n",
        "        for ind, satellite in enumerate(self.data['sat_id'].unique()):\n",
        "            sat_data = self.data.query('sat_id==@satellite').iloc[:, 1:]\n",
        "            sequence_count = np.ceil(sat_data.shape[0] / self.sequence_length).astype('int')\n",
        "\n",
        "            samples_sat = np.zeros((sequence_count * self.sequence_length, sat_data.shape[1]))\n",
        "            samples_sat[: sat_data.shape[0]] = sat_data.values\n",
        "\n",
        "            self.satellite_dict[ind] = samples_sat.reshape(sequence_count, self.sequence_length, -1)\n",
        "\n",
        "    def generate_samples(self, max_sequence_count=10, last_sequence=False):\n",
        "        # генерирует отдельные наборы последовательных секвенций, аугментируя данные: \n",
        "        # разбивает данные по одному спутнику (если их больше, чем max_sequence_count)\n",
        "        # на несколько отдельных последовательностей \n",
        "        # для использования их при тренировке, как разных спутников.\n",
        "        self.samples = []\n",
        "        \n",
        "\n",
        "        for sat in self.satellite_dict.values():\n",
        "            sequence_count = sat.shape[0]\n",
        "            if not last_sequence:\n",
        "                sequence_count -= 1\n",
        "            if  sequence_count > max_sequence_count:\n",
        "                samples_count = math.ceil(sequence_count / max_sequence_count)\n",
        "                step = (sequence_count - max_sequence_count) / (samples_count - 1)\n",
        "                for sample in range(samples_count):\n",
        "                    next_step = round(step * sample)\n",
        "                    self.samples.append(self.data_casting(sat[next_step: next_step + max_sequence_count]))\n",
        "\n",
        "    @staticmethod\n",
        "    def data_casting(data):\n",
        "        # вычитает из значений симуляции начальную ошибку.\n",
        "        # начальная ошибка равна x_sym[0] - x[0] и аналогично для y, z и т.д.\n",
        "        for i in range(1, 7, 1):\n",
        "            data[..., i + 6] -= data[0, 0, i + 6] - data[0, 0, i]\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns total number of samples\n",
        "        \"\"\"\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        \n",
        "        :param index: \n",
        "        :return: one-satellite sample [max_sequence_count, sequence_length, gt + in values]\n",
        "        \"\"\"\n",
        "        return FloatTensor(self.samples[index])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "WpGAiMCM5eSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smape(satellite_predicted_values, satellite_true_values): \n",
        "    # the division, addition and subtraction are pointwise \n",
        "    return torch.mean(torch.abs(satellite_predicted_values - satellite_true_values) \n",
        "        / (torch.abs(satellite_predicted_values) + torch.abs(satellite_true_values)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vZCs2D1PYS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, loss_function, data, batch_size, optimizer=None, name=None, ):\n",
        "    \"\"\"\n",
        "    #TO DO: описание\n",
        "    \"\"\"\n",
        "    epoch_loss = 0\n",
        "    epoch_SGP4_loss = 0\n",
        "    epoch_smape = 0\n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    max_sequence_count, sequence_length = data[0].shape[0], data[0].shape[1]\n",
        "    batch_count = len(loader)\n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batch_count) as progress_bar:               \n",
        "            for i, sample in enumerate(loader):\n",
        "                sample = sample.permute(1, 2, 0, 3)  # [max_sequence_count, sequence_length,  batch, gt + in values]\n",
        "                h, c = model.init_hidden(sample.shape[2])\n",
        "                for sequence in sample:\n",
        "                    X_batch, y_batch = (sequence[...,:7]).to(device), (sequence[...,7:]).to(device)\n",
        "                    \n",
        "                    prediction, (h_1, c_1) = model(X_batch, h, c)\n",
        "                    \n",
        "                    loss = loss_function(prediction, y_batch)\n",
        "                    SGP4_loss = loss_function(X_batch[...,1:], y_batch)\n",
        "                    epoch_smape += smape(prediction.detach(),\n",
        "                                         y_batch.detach())\n",
        "                    \n",
        "                    epoch_loss += loss.item()\n",
        "                    epoch_SGP4_loss += SGP4_loss.item()\n",
        "\n",
        "                    if is_train:\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                \n",
        "                    h, c = h_1.detach(), c_1.detach()\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
        "                    name, loss.item())\n",
        "                )\n",
        "            \n",
        "            epoch_loss /= (i + 1) * max_sequence_count\n",
        "            epoch_SGP4_loss /= (i + 1) * max_sequence_count\n",
        "            epoch_smape /= (i + 1) * max_sequence_count\n",
        "            score = (1-epoch_smape) * 100\n",
        "\n",
        "            loss_comparison = epoch_loss / epoch_SGP4_loss\n",
        "            \n",
        "            progress_bar.set_description(f'Epoch {name} - loss compar: {loss_comparison:.2f}, '\n",
        "                                         f'score: {score:.2f}, loss: {epoch_loss:.5f}')\n",
        "\n",
        "    return float(score)\n",
        "\n",
        "\n",
        "def fit(model, data, folds, loss_function, default_state, optimizer=None, \n",
        "        epochs_count=1, batch_size=1, plot_draw=False):\n",
        "    \"\"\"\n",
        "    тренировка модели с кросс-валидацией и валидацией после каждой эпохи, валидация есть по умолчанию.\n",
        "    Выводит списки fold_train_history fold_val_history.\n",
        "    \"\"\"\n",
        "    fold_train_history = []\n",
        "    fold_val_history = []\n",
        "    for j, fold in enumerate(folds):\n",
        "\n",
        "        #Возврат оптимизатора к изначальным значениям\n",
        "        optimizer.load_state_dict(default_state)\n",
        "\n",
        "        #Scheduler на каждом фолде заново определяется\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor = 0.8, patience = 10, verbose = True, threshold= 1e-1)\n",
        "\n",
        "        #Сброс параметров модели на каждом фолде\n",
        "        for name, module in model.named_children():\n",
        "            print('resetting ', name)\n",
        "            module.reset_parameters()\n",
        "        \n",
        "        print('Fold: ', j+1, '\\n')\n",
        "        \n",
        "        \n",
        "        val_data = data.loc[fold]\n",
        "        val_dataset = Data_Sat(val_data, sequence_length)\n",
        "        val_dataset.generate_samples(max_sequence_count=max_sequence_count,  last_sequence=False)\n",
        "\n",
        "        train_data = data.loc[[index for nfold in folds for index in nfold if nfold != fold]]\n",
        "        train_dataset = Data_Sat(train_data, sequence_length)\n",
        "        train_dataset.generate_samples(max_sequence_count=max_sequence_count, last_sequence=False)\n",
        "\n",
        "        train_history = []\n",
        "        val_history = []\n",
        "\n",
        "        for epoch in range(epochs_count):\n",
        "\n",
        "            for param_group in optimizer.param_groups: \n",
        "              print('\\nLR: ', param_group['lr'])\n",
        "\n",
        "            name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "            if train_dataset:\n",
        "                epoch_train_score = do_epoch(model, loss_function, train_dataset, batch_size, \n",
        "                                              optimizer, name_prefix + 'Train:')\n",
        "                train_history.append(epoch_train_score)\n",
        "\n",
        "\n",
        "            if val_dataset:\n",
        "                name = '  Val:'\n",
        "                if not train_dataset:\n",
        "                    name = ' Test:'\n",
        "                epoch_val_score = do_epoch(model, loss_function, val_dataset, batch_size, \n",
        "                                             optimizer=None, name=name_prefix + name)\n",
        "                val_history.append(epoch_val_score)\n",
        "                scheduler.step(epoch_val_score)\n",
        "        if plot_draw:\n",
        "            draw_plot(train_history, val_history)\n",
        "        fold_val_history.append(val_history[-1])\n",
        "        fold_train_history.append(train_history[-1])\n",
        "    return fold_train_history, fold_val_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "PZxEdUTe5eSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_plot(train_loss_history, val_loss_history):\n",
        "    \"\"\"\n",
        "    Рисует lineplot\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame(data=[train_loss_history, val_loss_history], index=['Train', 'Val']).T\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    sns.set(style='darkgrid')\n",
        "    ax = sns.lineplot(data=data, markers = [\"o\", \"o\"], palette='bright')\n",
        "    plt.title(\"Line Plot\", fontsize = 20)\n",
        "    plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "    plt.ylabel(\"Loss\", fontsize = 15)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "Ij9SXAAk5eSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim=7, output_dim=6, lstm_hidden_dim=20, \n",
        "                 lstm_layers_count=1, bidirectional=False, dropout=0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = input_dim \n",
        "        self.lstm_layers_count = lstm_layers_count\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "            \n",
        "        self.lstm = nn.LSTM(input_size = self.input_dim, \n",
        "                            hidden_size = self.lstm_hidden_dim,\n",
        "                            num_layers = self.lstm_layers_count,\n",
        "                            bidirectional=bidirectional,\n",
        "                            bias=True,\n",
        "                            dropout=dropout\n",
        "                           )\n",
        "        \n",
        "        self.linear = nn.Linear(lstm_hidden_dim, output_dim, bias=True)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        \n",
        "            return (torch.zeros(self.lstm_layers_count * (2 if bidirectional else 1), \n",
        "                                batch_size, self.lstm_hidden_dim).to(device),\n",
        "                    torch.zeros(self.lstm_layers_count * (2 if bidirectional else 1), \n",
        "                                batch_size, self.lstm_hidden_dim).to(device)\n",
        "                   )\n",
        "\n",
        "        \n",
        "    def forward(self, inputs, h, c):\n",
        "        \n",
        "        lstm_out, (h_1, c_1) = self.lstm.forward(inputs, (h, c))\n",
        "        linear_out = self.linear.forward(lstm_out)\n",
        "        \n",
        "        return linear_out, (h_1, c_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO-9QFlZUiu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, sat_data):\n",
        "    \"\"\"\n",
        "    Получает на вход модель и разделенные на sequences_count, sequence_length данные. Предсказывает реальные значение по спутнику.\n",
        "    Выводит Tensor формы (n_samples, n_features).\n",
        "    \"\"\"\n",
        "    sequences_count, sequence_length, _ = sat_data.shape\n",
        "    result = torch.zeros((sequences_count*sequence_length, 6)).to(device)\n",
        "    model.eval()\n",
        "    h, c = model.init_hidden(1)\n",
        "    for i, seq in enumerate(sat_data):\n",
        "        inputs = FloatTensor(seq[:, None, :])\n",
        "        predicted, (h_1, c_1) = model(inputs, h, c)\n",
        "        \n",
        "        h, c = h_1.detach(), c_1.detach()\n",
        "        predicted = predicted.view(sequence_length, -1).detach()\n",
        "        result[i*sequence_length : (i+1)*sequence_length] = predicted\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9dwwtQNSNoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data preparation\n",
        "data = pd.read_csv(data_folder + 'train.csv', parse_dates=['epoch'])\n",
        "columns = ['sat_id', 'delta_seconds', 'x_sim', 'y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim',\n",
        "           'x', 'y', 'z', 'Vx', 'Vy', 'Vz']\n",
        "data_with_dt = add_delta_time(data, columns)\n",
        "data_with_dt.set_index(keys='sat_id', drop=False, inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRbHIgL3SirL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data normalization\n",
        "normalizer = Norm(data_with_dt, ['sat_id'])\n",
        "norm_data = normalizer.l2_norm(data_with_dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeuctV8SpuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data splitting\n",
        "np.random.seed(42)\n",
        "\n",
        "train_indices, test_indices = split_data(len(data['sat_id'].unique()))\n",
        "folds = split_folds(train_indices, 5)\n",
        "test_data = norm_data.loc[test_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "ZB3vpZJw5eSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data settings\n",
        "sequence_length = 50\n",
        "max_sequence_count = 50\n",
        "\n",
        "# train settings\n",
        "batch_size = 5\n",
        "epoch_count = 2\n",
        "plot_draw = True\n",
        "\n",
        "# optimizer settings\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 0\n",
        "\n",
        "# model settings\n",
        "lstm_hidden_dim = 50\n",
        "lstm_hidden_lauers_count = 1\n",
        "bidirectional = False\n",
        "dropout = 0\n",
        "\n",
        "#train_dataset = Data_Sat(train_data, sequence_length)\n",
        "#train_dataset.generate_samples(max_sequence_count=max_sequence_count, last_sequence=False)\n",
        "#val_dataset = Data_Sat(val_data, sequence_length)\n",
        "#val_dataset.generate_samples(max_sequence_count=max_sequence_count,  last_sequence=False)\n",
        "#print('Samples count:', len(train_dataset))\n",
        "\n",
        "model = LSTM(lstm_hidden_dim=lstm_hidden_dim,\n",
        "             lstm_layers_count=lstm_hidden_lauers_count,\n",
        "             bidirectional=bidirectional,\n",
        "             dropout=dropout,\n",
        "            ).to(device)\n",
        "\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "                        model.parameters(),\n",
        "                        lr=learning_rate, \n",
        "                        weight_decay=weight_decay\n",
        "                    )\n",
        "default_state = optimizer.state_dict()                              #Нужно ли обновлять optimizer на каждом фолде?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6hcM_Y55eSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_hist, val_hist = fit(model, norm_data, folds, loss_function, default_state, optimizer, epochs_count=epoch_count,\n",
        "    batch_size=batch_size, plot_draw=plot_draw\n",
        "   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glCcoFQsWr58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Mean_train_score: ', np.mean(tr_hist), ' Mean_val_score: ', np.mean(val_hist))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0K84BrVXMkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict test and compute score\n",
        "\n",
        "test_dataset = Data_Sat(test_data, sequence_length)\n",
        "test_dataset.generate_samples(max_sequence_count=50)\n",
        "\n",
        "metric = 0\n",
        "\n",
        "for sat in test_dataset.satellite_dict:\n",
        "    sat_data = test_dataset.satellite_dict[sat]\n",
        "    X = FloatTensor(sat_data[..., :7]).to(device)\n",
        "    y = FloatTensor(sat_data[..., 7:]).view(-1, 6).to(device)\n",
        "    predicts = predict(model, X)[y!=0].view(-1, 6)\n",
        "    metric += smape(predicts, \n",
        "                    y[y!=0].view(-1, 6)\n",
        "                   )\n",
        "    \n",
        "metric /= len(test_dataset.satellite_dict)\n",
        "score = (1-metric)*100\n",
        "print('Test score: ', int(score.cpu()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "SanyVJSV5eSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit(model, loss_function, val_data=test_dataset)\n",
        "#test_submit = pd.read_csv('data/Track 1/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}