{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWUsszxxiXPH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fctMNraAwSdh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    from torch import FloatTensor, LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRfDlcBTiid9"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv', parse_dates=['epoch']).iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i3nl9_iVcEl"
   },
   "outputs": [],
   "source": [
    "data.set_index(keys=data['sat_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm = Normalizer()\n",
    "# normalized = norm.fit_transform(data.loc[:, data.columns != 'sat_id'])\n",
    "# data.loc[:, data.columns != 'sat_id'] = normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJHqM3j3wVHt"
   },
   "outputs": [],
   "source": [
    "def split_data(values, coeff=0.7):\n",
    "  split = int(np.floor(coeff * values))\n",
    "  split2 = int(np.floor(values*(1-coeff)/2))\n",
    "  indices = list(range(values))\n",
    "  np.random.shuffle(indices)\n",
    "  train_indices, val_indices, test_indices = indices[:split], indices[split:split+split2], indices[split+split2:]\n",
    "  return train_indices, val_indices, test_indices\n",
    "\n",
    "train_indices, val_indices, test_indices = split_data(len(data['sat_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yHF-S2wQHAO"
   },
   "outputs": [],
   "source": [
    "train_data = data.loc[train_indices]\n",
    "test_data = data.loc[test_indices]\n",
    "val_data = data.loc[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GE1FyDjbGX3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples count: 151\n"
     ]
    }
   ],
   "source": [
    "class Data_Sat(Dataset):\n",
    "    def __init__(self, data, sequence_duration=20, normalizer=None):\n",
    "        self.sequence_duration = sequence_duration\n",
    "        self.data = data\n",
    "        self.satellite_dict = {}\n",
    "        self.normalizer = normalizer\n",
    "        self.split_data()\n",
    "\n",
    "    def split_data(self):\n",
    "      for ind, satellite in enumerate(self.data['sat_id'].unique()):\n",
    "            sat_data = self.data.query('sat_id==@satellite').iloc[:,1:]\n",
    "            sequence_count = np.floor(sat_data.shape[0] / self.sequence_duration).astype('int')\n",
    "\n",
    "            samples_sat = np.zeros((sequence_count * self.sequence_duration, 12))\n",
    "            samples_sat = sat_data.iloc[: sequence_count * self.sequence_duration].values\n",
    "            if self.normalizer:\n",
    "                samples_sat = self.normalizer.fit_transform(samples_sat)\n",
    "\n",
    "            self.satellite_dict[ind] = samples_sat.reshape(sequence_count, self.sequence_duration, 12)\n",
    "\n",
    "        \n",
    "        \n",
    "    def sample_generator(self, max_sequence_count=10):\n",
    "      self.samples = []\n",
    "\n",
    "      for sat in self.satellite_dict.values():\n",
    "        if sat.shape[0] > max_sequence_count:\n",
    "          sequence_count = sat.shape[0]\n",
    "          numb_samples = math.ceil(sequence_count / max_sequence_count)\n",
    "          step = (sequence_count - max_sequence_count)/(numb_samples-1)\n",
    "          for sample in range(numb_samples):\n",
    "            next_step = round(step*sample)\n",
    "            \n",
    "            self.samples.append(self.data_casting(sat[next_step: next_step + max_sequence_count]))\n",
    "            # break\n",
    "\n",
    "    def data_casting(self, data):\n",
    "      for i in range(6):\n",
    "        data[...,i+6] -= data[0, 0, i+6] - data[0, 0, i]\n",
    "      return data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns total number of samples\n",
    "        '''\n",
    "        return len(self.samples)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return torch.Tensor(self.samples[index]).type(torch.FloatTensor)\n",
    "\n",
    "dataset = Data_Sat(train_data, 20, Normalizer())\n",
    "dataset.sample_generator(max_sequence_count=100)\n",
    "print('Samples count:',len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20, 12])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=1) as progress_bar:\n",
    "            for i, sample in enumerate(data):\n",
    "                sample = sample.permute(1, 2, 0, 3)\n",
    "                for sequence in sample:\n",
    "                    X_batch, y_batch = (sequence[...,6:]).to(device), (sequence[...,:6]).to(device)\n",
    "                    logits = model(X_batch)\n",
    "\n",
    "\n",
    "                    loss = criterion(logits, y_batch)\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    if optimizer:\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "#                     indices = torch.max(logits, dim=2)[1]   \n",
    "                # correct_samples = float(torch.sum(indices[y_batch!=0] == y_batch[y_batch!=0]))\n",
    "                \n",
    "                # cur_correct_count, cur_sum_count = correct_samples, y_batch[y_batch!=0].shape[0]\n",
    "\n",
    "                # correct_count += cur_correct_count\n",
    "                # sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
    "                    name, loss.item())\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
    "                name, epoch_loss)\n",
    "            )\n",
    "\n",
    "    return epoch_loss #/ batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=1,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=6, output_dim=6, lstm_hidden_dim=28, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 6, \n",
    "                            hidden_size = lstm_hidden_dim,\n",
    "                            num_layers = lstm_layers_count,\n",
    "                            bias=True)\n",
    "        \n",
    "        self.linear = nn.Linear(lstm_hidden_dim, 6, bias=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        lstm_out, _ = self.lstm.forward(inputs)\n",
    "        linear_out = self.linear.forward(lstm_out)\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample_generator(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 57.99253: : 31it [00:16,  1.87it/s]                                                             \n",
      "[2 / 20] Train: Loss = 42.18295: : 31it [00:15,  1.94it/s]                                                             \n",
      "[3 / 20] Train: Loss = 37.78740: : 31it [00:15,  1.99it/s]                                                             \n",
      "[4 / 20] Train: Loss = 34.42522: : 31it [00:16,  1.89it/s]                                                             \n",
      "[5 / 20] Train: Loss = 31.41215: : 31it [00:15,  1.99it/s]                                                             \n",
      "[6 / 20] Train: Loss = 29.86184: : 31it [00:15,  1.99it/s]                                                             \n",
      "[7 / 20] Train: Loss = 28.82684: : 31it [00:16,  1.93it/s]                                                             \n",
      "[8 / 20] Train: Loss = 28.21421: : 31it [00:17,  1.76it/s]                                                             \n",
      "[9 / 20] Train: Loss = 27.51537: : 31it [00:17,  1.73it/s]                                                             \n",
      "[10 / 20] Train: Loss = 26.70197: : 31it [00:17,  1.74it/s]                                                            \n",
      "[11 / 20] Train: Loss = 26.42760: : 31it [00:18,  1.72it/s]                                                            \n",
      "[12 / 20] Train: Loss = 25.77632: : 31it [00:17,  1.77it/s]                                                            \n",
      "[13 / 20] Train: Loss = 25.39790: : 31it [00:17,  1.76it/s]                                                            \n",
      "[14 / 20] Train: Loss = 24.98259: : 31it [00:17,  1.77it/s]                                                            \n",
      "[15 / 20] Train: Loss = 24.57525: : 31it [00:17,  1.81it/s]                                                            \n",
      "[16 / 20] Train: Loss = 24.06350: : 31it [00:16,  1.93it/s]                                                            \n",
      "[17 / 20] Train: Loss = 23.44595: : 31it [00:16,  1.92it/s]                                                            \n",
      "[18 / 20] Train: Loss = 22.98218: : 31it [00:16,  1.88it/s]                                                            \n",
      "[19 / 20] Train: Loss = 22.52976: : 31it [00:15,  1.95it/s]                                                            \n",
      "[20 / 20] Train: Loss = 22.13009: : 31it [00:16,  1.94it/s]                                                            \n"
     ]
    }
   ],
   "source": [
    "model = LSTM().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=5)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "fit(model, criterion, optimizer, train_loader, epochs_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.862394\n",
      "0.04478041\n",
      "----------------------------------------\n",
      "5.143427\n",
      "0.06495157\n",
      "----------------------------------------\n",
      "5.618558\n",
      "0.07677948\n",
      "----------------------------------------\n",
      "5.847515\n",
      "0.089028046\n",
      "----------------------------------------\n",
      "5.415056\n",
      "0.09592889\n",
      "----------------------------------------\n",
      "4.752852\n",
      "0.064746186\n",
      "----------------------------------------\n",
      "4.8363447\n",
      "0.07796332\n",
      "----------------------------------------\n",
      "5.135434\n",
      "0.12014823\n",
      "----------------------------------------\n",
      "5.5949173\n",
      "0.14244026\n",
      "----------------------------------------\n",
      "5.8196473\n",
      "0.1544064\n",
      "----------------------------------------\n",
      "5.398607\n",
      "0.1536307\n",
      "----------------------------------------\n",
      "4.736269\n",
      "0.106220216\n",
      "----------------------------------------\n",
      "4.812337\n",
      "0.1267317\n",
      "----------------------------------------\n",
      "5.1309786\n",
      "0.18440634\n",
      "----------------------------------------\n",
      "5.5727262\n",
      "0.20859644\n",
      "----------------------------------------\n",
      "5.798735\n",
      "0.21959248\n",
      "----------------------------------------\n",
      "5.383205\n",
      "0.21421944\n",
      "----------------------------------------\n",
      "4.7232423\n",
      "0.14984547\n",
      "----------------------------------------\n",
      "4.789369\n",
      "0.17755121\n",
      "----------------------------------------\n",
      "5.126301\n",
      "0.25068086\n",
      "----------------------------------------\n",
      "5.5505295\n",
      "0.27748102\n",
      "----------------------------------------\n",
      "5.777015\n",
      "0.28866082\n",
      "----------------------------------------\n",
      "5.36697\n",
      "0.2784425\n",
      "----------------------------------------\n",
      "4.7120485\n",
      "0.19585201\n",
      "----------------------------------------\n",
      "4.7675776\n",
      "0.23030269\n",
      "----------------------------------------\n",
      "5.121193\n",
      "0.31767\n",
      "----------------------------------------\n",
      "5.5287905\n",
      "0.34536117\n",
      "----------------------------------------\n",
      "5.7555065\n",
      "0.35498703\n",
      "----------------------------------------\n",
      "5.3510575\n",
      "0.33915195\n",
      "----------------------------------------\n",
      "4.701259\n",
      "0.23900722\n",
      "----------------------------------------\n",
      "4.74732\n",
      "0.2795917\n",
      "----------------------------------------\n",
      "5.115931\n",
      "0.38042054\n",
      "----------------------------------------\n",
      "5.507767\n",
      "0.41015095\n",
      "----------------------------------------\n",
      "5.734296\n",
      "0.41984385\n",
      "----------------------------------------\n",
      "5.3348565\n",
      "0.40014833\n",
      "----------------------------------------\n",
      "4.691321\n",
      "0.2833758\n",
      "----------------------------------------\n",
      "4.726843\n",
      "0.33093393\n",
      "----------------------------------------\n",
      "5.110803\n",
      "0.44607484\n",
      "----------------------------------------\n",
      "5.485838\n",
      "0.47840786\n",
      "----------------------------------------\n",
      "5.7120905\n",
      "0.48772076\n",
      "----------------------------------------\n",
      "5.318036\n",
      "0.4629494\n",
      "----------------------------------------\n",
      "4.682949\n",
      "0.3282774\n",
      "----------------------------------------\n",
      "4.7065716\n",
      "0.3823278\n",
      "----------------------------------------\n",
      "5.10574\n",
      "0.5102019\n",
      "----------------------------------------\n",
      "5.4644337\n",
      "0.5437436\n",
      "----------------------------------------\n",
      "5.6906223\n",
      "0.5519878\n",
      "----------------------------------------\n",
      "5.302243\n",
      "0.5223106\n",
      "----------------------------------------\n",
      "4.676137\n",
      "0.37088215\n",
      "----------------------------------------\n",
      "4.6881285\n",
      "0.43194687\n",
      "----------------------------------------\n",
      "5.1031694\n",
      "0.57330275\n",
      "----------------------------------------\n",
      "5.443895\n",
      "0.60983694\n",
      "----------------------------------------\n",
      "5.6698294\n",
      "0.6188463\n",
      "----------------------------------------\n",
      "5.285668\n",
      "0.5854595\n",
      "----------------------------------------\n",
      "4.6695395\n",
      "0.4166323\n",
      "----------------------------------------\n",
      "4.6719794\n",
      "0.48574948\n",
      "----------------------------------------\n",
      "5.102516\n",
      "0.6417452\n",
      "----------------------------------------\n",
      "5.423311\n",
      "0.6808225\n",
      "----------------------------------------\n",
      "5.6482997\n",
      "0.68925846\n",
      "----------------------------------------\n",
      "5.2685494\n",
      "0.6504581\n",
      "----------------------------------------\n",
      "4.663276\n",
      "0.4625999\n",
      "----------------------------------------\n",
      "4.6553335\n",
      "0.53912866\n",
      "----------------------------------------\n",
      "5.10122\n",
      "0.708925\n",
      "----------------------------------------\n",
      "5.402418\n",
      "0.7499753\n",
      "----------------------------------------\n",
      "5.6269236\n",
      "0.75790966\n",
      "----------------------------------------\n",
      "5.2513514\n",
      "0.71436906\n",
      "----------------------------------------\n",
      "4.6567063\n",
      "0.5082153\n",
      "----------------------------------------\n",
      "4.638107\n",
      "0.5927742\n",
      "----------------------------------------\n",
      "5.099905\n",
      "0.777565\n",
      "----------------------------------------\n",
      "5.3815536\n",
      "0.8218193\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence_duration = 20\n",
    "val_dataset = Data_Sat(val_data, sequence_duration, Normalizer())\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "for batch in val_dataset.satellite_dict[1]:\n",
    "    model.train(False)\n",
    "    batch = batch.reshape(sequence_duration, 1, -1)\n",
    "    X_batch, y_batch = FloatTensor(batch[...,6:]), FloatTensor(batch[...,:6]).detach().to(\"cpu\").numpy().reshape(sequence_duration,-1)\n",
    "    \n",
    "    predict = model(X_batch).detach().to(\"cpu\").numpy().reshape(sequence_duration,-1)\n",
    "    with_model = predict - y_batch\n",
    "    without_model = X_batch.detach().to(\"cpu\").numpy().reshape(sequence_duration,-1) - y_batch\n",
    "    print(abs(with_model).sum())\n",
    "    print(abs(without_model).sum())\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "#     break\n",
    "#     scaler.fit(predict.detach())\n",
    "#     print(scaler.inverse_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNn/CRuVT+ZEGb/VmOyLWIL",
   "collapsed_sections": [],
   "name": "IDAO.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
