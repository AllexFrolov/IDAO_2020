{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWUsszxxiXPH",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fctMNraAwSdh",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device('cuda:0')\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    \n",
    "try:\n",
    "    from google.colab import drive\n",
    "    is_in_colab = True\n",
    "except:\n",
    "    is_in_colab = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# вывод информации о выданном с colab GPU\n",
    "if is_in_colab:\n",
    "    !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "    !pip install gputil\n",
    "    !pip install psutil\n",
    "    !pip install humanize\n",
    "    import psutil\n",
    "    import humanize\n",
    "    import os\n",
    "    import GPUtil as GPU\n",
    "    GPUs = GPU.getGPUs()\n",
    "    gpu = GPUs[0]\n",
    "    def printm():\n",
    "        process = psutil.Process(os.getpid())\n",
    "        print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "        print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "\n",
    "    printm()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if is_in_colab:\n",
    "    drive.mount('/content/drive')\n",
    "    data_folder = r'/content/drive/My Drive/Colab/IDAO_2020/'\n",
    "else:\n",
    "    data_folder = r'./data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# баш команда для создания каталога в монитрованном гугл-диске, для хранения там данных. \n",
    "# Выполните один раз после монтирования диска, чтобы не создавать папку вручную\n",
    "# ! mkdir -p '/content/drive/My Drive/Colab/IDAO_2020/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(path, model, optimizer, loss_history, train_history, val_history):\n",
    "    torch.save({\n",
    "            'epoch': len(train_histor),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_history[-1],\n",
    "            'loss_history': loss_history,\n",
    "            'train_history': train_history,\n",
    "            'val_history': val_history\n",
    "            }, path)\n",
    "    print('successfully saved')\n",
    "    \n",
    "def load_model(path, model, optimizer, loss_history, train_history, val_history):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss_history = checkpoint['loss_history']\n",
    "    train_history = checkpoint['train_history']\n",
    "    val_history = checkpoint['val_history']\n",
    "    print('successfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRfDlcBTiid9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_folder + 'train.csv', parse_dates=['epoch']).iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i3nl9_iVcEl",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data.set_index(keys=data['sat_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Norm():\n",
    "    \"\"\"\n",
    "    Нормализатор. \n",
    "    Init запоминает среднее и стандартное отклонение в данных\n",
    "    \"\"\"\n",
    "    def __init__(self, data, ignore_column=None):\n",
    "        self.mean = data.mean()\n",
    "        self.std = data.std()\n",
    "        if ignore_column:\n",
    "            self.mean[ignore_column] = 0\n",
    "            self.std[ignore_column] = 1\n",
    "        \n",
    "    def z_norm(self, data, columns=None):\n",
    "        if not columns:\n",
    "            columns = data.columns\n",
    "        return (data[columns] - self.mean[columns]) / self.std[columns]\n",
    "    \n",
    "    def back_norm(self, data, columns=None):\n",
    "        try:\n",
    "            if not columns:\n",
    "                columns = data.columns\n",
    "        except:\n",
    "            print(\"data должен быть DataFrame или columns должен быть заполнен\")\n",
    "            return None\n",
    "        if not type(data) is pd.core.frame.DataFrame:\n",
    "            data = pd.DataFrame(data=data, columns=columns)\n",
    "            \n",
    "        return (data[columns] * self.std[columns]  + self.mean[columns])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalizer = Norm(data, ['sat_id'])\n",
    "norm_data = normalizer.z_norm(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJHqM3j3wVHt",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def split_data(values, coeff=0.7):\n",
    "    # coeff - доля трейна, остальное делится на валидацию и тест поровну\n",
    "    split = int(np.floor(coeff * values))\n",
    "    split2 = int(np.floor(values*(1-coeff)/2))\n",
    "    indices = list(range(values))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices, test_indices = indices[:split], indices[split:split+split2], indices[split+split2:]\n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "train_indices, val_indices, test_indices = split_data(len(data['sat_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yHF-S2wQHAO",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = norm_data.loc[train_indices]\n",
    "test_data = norm_data.loc[test_indices]\n",
    "val_data = norm_data.loc[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GE1FyDjbGX3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Data_Sat(Dataset):\n",
    "    def __init__(self, data, sequence_length=20):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.data = data\n",
    "        self.satellite_dict = {}\n",
    "        self.normalizer = normalizer\n",
    "        self.split_data()\n",
    "\n",
    "    def split_data(self):\n",
    "        # разделяет данные по каждому спутнику на отдельные секвенции длиной sequence_length каждая\n",
    "        # и записывает их в словарь self.satellite_dict\n",
    "        # нормализует данные\n",
    "\n",
    "        for ind, satellite in enumerate(self.data['sat_id'].unique()):\n",
    "            sat_data = self.data.query('sat_id==@satellite').iloc[:, 1:]\n",
    "            sequence_count = np.floor(sat_data.shape[0] / self.sequence_length).astype('int')\n",
    "\n",
    "            samples_sat = np.zeros((sequence_count * self.sequence_length, 12))\n",
    "            samples_sat = sat_data.iloc[: sequence_count * self.sequence_length].values\n",
    "\n",
    "            self.satellite_dict[ind] = samples_sat.reshape(sequence_count, self.sequence_length, 12)\n",
    "\n",
    "    def generate_samples(self, max_sequence_count=10):\n",
    "        # генерирует отдельные наборы последовательных секвенций, аугментируя данные: \n",
    "        # разбивает данные по одному спутнику (если их больше, чем max_sequence_count)\n",
    "        # на несколько отдельных последовательностей \n",
    "        # для использования их при тренировке, как разных спутников.\n",
    "        self.samples = []\n",
    "\n",
    "        for sat in self.satellite_dict.values():\n",
    "            if sat.shape[0] > max_sequence_count:\n",
    "                sequence_count = sat.shape[0]\n",
    "                samples_count = math.ceil(sequence_count / max_sequence_count)\n",
    "                step = (sequence_count - max_sequence_count) / (samples_count - 1)\n",
    "                for sample in range(samples_count):\n",
    "                    next_step = round(step * sample)\n",
    "                    self.samples.append(self.data_casting(sat[next_step: next_step + max_sequence_count]))\n",
    "\n",
    "    @staticmethod\n",
    "    def data_casting(data):\n",
    "        # вычитает из значений симуляции начальную ошибку.\n",
    "        # начальная ошибка равна x_sym[0] - x[0] и аналогично для y, z и т.д.\n",
    "        for i in range(6):\n",
    "            data[..., i + 6] -= data[0, 0, i + 6] - data[0, 0, i]\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns total number of samples\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param index: \n",
    "        :return: one-satellite sample [max_sequence_count, sequence_length, gt + in values]\n",
    "        \"\"\"\n",
    "        return FloatTensor(self.samples[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, loss_function, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    epoch_SGP4_loss = 0\n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "    max_sequence_count, sequence_length = data[0].shape[0], data[0].shape[1]\n",
    "    batch_count = len(loader)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batch_count) as progress_bar:\n",
    "            for i, sample in enumerate(loader):\n",
    "                sample = sample.permute(1, 2, 0, 3)  # [max_sequence_count, sequence_length,  batch, gt + in values]\n",
    "                previous_predicts = torch.zeros(sequence_length, sample.shape[2], 6).to(device)\n",
    "                for sequence in sample:\n",
    "                    X_batch, y_batch = (sequence[...,6:]).to(device), (sequence[...,:6]).to(device)\n",
    "                    inputs = torch.cat((X_batch, previous_predicts), dim=-1)\n",
    "                    \n",
    "                    prediction = model(inputs)\n",
    "                    \n",
    "                    loss = loss_function(prediction, y_batch)\n",
    "                    SGP4_loss = loss_function(X_batch, y_batch)\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "                    epoch_SGP4_loss += SGP4_loss.item()\n",
    "\n",
    "                    if is_train:\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    previous_predicts[0] = prediction[-1].detach()\n",
    "                \n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
    "                    name, loss.item())\n",
    "                )\n",
    "            \n",
    "            epoch_loss /= i * max_sequence_count\n",
    "            epoch_SGP4_loss /= i * max_sequence_count\n",
    "            \n",
    "#             print(f'Epoch {name} - loss: {epoch_loss:.5f} , SGP4 loss: {epoch_SGP4_loss:.5f}')\n",
    "            progress_bar.set_description(f'Epoch {name} - loss: {epoch_loss:.5f}, SGP4 loss: {epoch_SGP4_loss:.5f}')\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def fit(model, loss_function, optimizer=None, train_data=None, epochs_count=1, batch_size=1,\n",
    "        val_data=None, val_batch_size=None, plot_draw=False):\n",
    "    \"\"\"\n",
    "    тренировко модели с валидацией после каждой эпохи, если валидация задана\n",
    "    \"\"\"\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "        \n",
    "    if val_data and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        if train_data:\n",
    "            train_history.append(do_epoch(model, loss_function, train_data, batch_size, \n",
    "                                          optimizer, name_prefix + 'Train:')\n",
    "                                )\n",
    "\n",
    "        if val_data:\n",
    "            name = '  Val:'\n",
    "            if not train_data:\n",
    "                name = ' Test:'\n",
    "            val_history.append(do_epoch(model, loss_function, val_data, val_batch_size, \n",
    "                                         optimizer=None, name=name_prefix + name)\n",
    "                             )\n",
    "    if plot_draw:\n",
    "        draw_plot(train_history, val_history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def draw_plot(train_loss_history, val_loss_history):\n",
    "    \"\"\"\n",
    "    Рисует lineplot\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(data=[train_loss_history, val_loss_history], index=['Train', 'Val']).T\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.set(style='darkgrid')\n",
    "    ax = sns.lineplot(data=data, markers = [\"o\", \"o\"], palette='bright')\n",
    "    plt.title(\"Line Plot\", fontsize = 20)\n",
    "    plt.xlabel(\"Epoch\", fontsize = 15)\n",
    "    plt.ylabel(\"Loss\", fontsize = 15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=12, output_dim=6, lstm_hidden_dim=20, \n",
    "                 lstm_layers_count=1, bidirectional=False, dropout=0\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm_layers_count = lstm_layers_count\n",
    "        self.lstm_hidden_dim = lstm_hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = input_dim, \n",
    "                            hidden_size = lstm_hidden_dim,\n",
    "                            num_layers = lstm_layers_count,\n",
    "                            bidirectional=bidirectional,\n",
    "                            bias=True,\n",
    "                            dropout=dropout\n",
    "                           )\n",
    "        \n",
    "        self.linear = nn.Linear(lstm_hidden_dim, output_dim, bias=True)\n",
    "        \n",
    "    #def init_hidden(self, batch_size):\n",
    "            #return (torch.zeros(self.lstm_layers_count * (2 if bidirectional else 1), batch_size, self.lstm_hidden_dim).to(device),\n",
    "                    #torch.zeros(self.lstm_layers_count * (2 if bidirectional else 1), batch_size, self.lstm_hidden_dim).to(device))\n",
    "\n",
    "    #def forward(self, inputs, h, c):\n",
    "    def forward(self, inputs):\n",
    "        #lstm_out, _ = self.lstm.forward(inputs, (h, c))\n",
    "        lstm_out, _ = self.lstm.forward(inputs)\n",
    "        linear_out = self.linear.forward(lstm_out)\n",
    "        return linear_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data settings\n",
    "sequence_length = 40\n",
    "max_sequence_count = 50\n",
    "\n",
    "# train settings\n",
    "batch_size = 5\n",
    "epoch_count = 10\n",
    "plot_draw = True\n",
    "\n",
    "# optimizer settings\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0\n",
    "\n",
    "# model settings\n",
    "lstm_hidden_dim = 4\n",
    "lstm_hidden_lauers_count = 1\n",
    "bidirectional = False\n",
    "dropout = 0\n",
    "\n",
    "train_dataset = Data_Sat(train_data, sequence_length)\n",
    "train_dataset.generate_samples(max_sequence_count=max_sequence_count)\n",
    "val_dataset = Data_Sat(val_data, sequence_length)\n",
    "val_dataset.generate_samples(max_sequence_count=max_sequence_count)\n",
    "print('Samples count:', len(train_dataset))\n",
    "\n",
    "model = LSTM(lstm_hidden_dim=lstm_hidden_dim,\n",
    "             lstm_layers_count=lstm_hidden_lauers_count,\n",
    "             bidirectional=bidirectional,\n",
    "             dropout=dropout\n",
    "            ).to(device)\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "                        model.parameters(),\n",
    "                        lr=learning_rate, \n",
    "                        weight_decay=weight_decay\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run with validation\n",
    "fit(model, loss_function, optimizer, train_dataset, epochs_count=epoch_count,\n",
    "    batch_size=batch_size, val_data=val_dataset, plot_draw=plot_draw\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = Data_Sat(test_data, sequence_length)\n",
    "test_dataset.generate_samples(max_sequence_count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fit(model, loss_function, val_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNn/CRuVT+ZEGb/VmOyLWIL",
   "collapsed_sections": [],
   "name": "IDAO.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}